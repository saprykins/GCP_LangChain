{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde76e4d-feb7-4e16-b1bd-8fb6a833cc0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Task 1. Install packages and import libraries\n",
    "!pip install asyncio==3.4.3 asyncpg==0.27.0 cloud-sql-python-connector[\"asyncpg\"]==1.2.3\n",
    "!pip install numpy==1.22.4 pandas==1.5.3\n",
    "!pip install pgvector==0.1.8\n",
    "!pip install langchain==0.0.196 transformers==4.30.1\n",
    "!pip install google-cloud-aiplatform==1.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0996bc96-204e-4c32-9963-edb0a821dd63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Install Vertex AI SDK & Other dependencies\n",
    "\n",
    "!sudo apt -y -qq install tesseract-ocr\n",
    "!sudo apt -y -qq install libtesseract-dev\n",
    "!sudo apt-get -y -qq install poppler-utils #required by PyPDF2 for page count and other pdf utilities\n",
    "!sudo apt-get -y -qq install python-dev libxml2-dev libxslt1-dev antiword unrtf poppler-utils pstotext tesseract-ocr flac ffmpeg lame libmad0 libsox-fmt-mp3 sox libjpeg-dev swig\n",
    "! pip install --upgrade google-cloud-aiplatform\n",
    "# LangChain\n",
    "! pip install langchain langchain-experimental langchain[docarray]\n",
    "! pip install pypdf\n",
    "! pip install shapely==2.0.0\n",
    "! pip install pydantic==1.10.8\n",
    "# Open source vector store\n",
    "! pip install chromadb==0.3.26\n",
    "! pip install typing-inspect==0.8.0 typing_extensions==4.5.0\n",
    "# For dense vector representations of text\n",
    "! pip install sentence-transformers\n",
    "! pip install langchain-google-vertexai\n",
    "! pip install -qU langchain-google-vertexai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b36a8e4-ea7b-410b-ae11-1275b662ce1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Automatically restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e22b08-4adc-4fb9-95b5-ec7fb7f6a261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import urllib\n",
    "import warnings\n",
    "from pathlib import Path as p\n",
    "\n",
    "import pandas as pd\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc6f525-9786-4569-aaac-9c005db08b5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Task 2. Load the model and prepare data\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = ChatVertexAI(model_name=\"gemini-pro\")\n",
    "#TODO: Load the pre-trained text generation model named gemini-pro using ChatVertexAI.\n",
    "#TODO: Load the pre-trained text generation model named Quicklab using ChatVertexAI.\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the URL and local path\n",
    "url = \"https://services.google.com/fh/files/misc/practitioners_guide_to_mlops_whitepaper.pdf\"\n",
    "local_path = Path(\"data/practitioners_guide_to_mlops_whitepaper.pdf\")\n",
    "\n",
    "# Create the 'data' directory if it doesn't exist\n",
    "local_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download and save the PDF file\n",
    "urllib.request.urlretrieve(url, local_path)\n",
    "\n",
    "#TODO: Download a PDF file from specified URL and save it in \"data\" directory\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load the PDF file\n",
    "pdf_loader = PyPDFLoader(str(local_path))\n",
    "\n",
    "# Load and split the PDF into individual pages\n",
    "pages = pdf_loader.load_and_split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb18acd5-29e8-4d16-ac00-0d27b740f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 3. Generate summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de464893-f82f-4be1-a37e-d8e4d0f57d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Prompt design with Stuffing Chain\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import vertexai\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms.vertexai import VertexAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain.chains import load_summarize_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the URL and local path\n",
    "url = \"https://services.google.com/fh/files/misc/practitioners_guide_to_mlops_whitepaper.pdf\"\n",
    "local_path = Path(\"data/practitioners_guide_to_mlops_whitepaper.pdf\")\n",
    "\n",
    "# Create the 'data' directory if it doesn't exist\n",
    "local_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download and save the PDF file\n",
    "urllib.request.urlretrieve(url, local_path)\n",
    "\n",
    "# Load the PDF file\n",
    "pdf_loader = PyPDFLoader(str(local_path))\n",
    "\n",
    "# Load and split the PDF into individual pages\n",
    "pages = pdf_loader.load_and_split()\n",
    "\n",
    "# Prepare the prompt template\n",
    "prompt_template = \"\"\"Write a concise summary of the following text delimited by triple backquotes.\n",
    "              Return your response in bullet points which covers the key points of the text.\n",
    "              ```{text}```\n",
    "              BULLET POINT SUMMARY:\n",
    "  \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "# Initialize the pre-trained model\n",
    "model = ChatVertexAI(model_name=\"gemini-pro\")\n",
    "\n",
    "# Load the summarization chain with the stuff method\n",
    "summarization_chain = load_summarize_chain(\n",
    "    llm=model,\n",
    "    chain_type=\"stuff\",\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "# Prepare the first three pages as documents\n",
    "input_documents = pages[:3]  # Use first three Document objects\n",
    "\n",
    "# Generate the summary\n",
    "summary = summarization_chain({\"input_documents\": input_documents})\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3883eb22-65cc-4af9-95d6-4873d6ddb5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 4. Add tools to the LLM for multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea98878d-d529-4e71-8867-7f1addd41b54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "llm = ChatVertexAI(model=\"gemini-pro\")\n",
    "import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433d86ac-087c-4ba5-a4ba-2c38b3fb99d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Subscribe To Quicklab :-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a3ab70-14de-4136-93bb-fe5934de5cf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7178fc8b-64be-4a1f-9685-bc702095bd9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TODO: Add the tools to the LLM created earlier and invoke it with the following query. Print the result in the console.\n",
    "from langchain_core.messages import HumanMessage, ToolMessage, AIMessage\n",
    "query = \"What is 3 * 12?\"\n",
    "messages = [HumanMessage(query)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27add25e-4e53-4ff7-943e-878720b6d84f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TODO: Iterate through the tools in the response, invoke the tools and append the response to the messages object.\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "always_multiply_llm = llm.bind_tools([multiply], tool_choice=\"multiply\")\n",
    "always_call_tool_llm = llm.bind_tools([add, multiply], tool_choice=\"any\")\n",
    "query = \"What is 3 * 12?\"\n",
    "\n",
    "llm_with_tools.invoke(query).tool_calls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22e1f67-13e7-4fdf-9da3-b598c87f6d1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers.openai_tools import PydanticToolsParser\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe40a1cf-8796-478a-81c9-804733802070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2efee6a-9760-4944-96ae-5c380ebffc7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
